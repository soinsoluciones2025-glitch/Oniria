// Purpose: Manages microphone input for real-time speech-to-text transcription.
// This is the core component of the Auditory Accessibility Module (AAM).
// It uses Android's built-in SpeechRecognizer for continuous voice recognition.
package com.oniria.modules.perception

import android.content.Context
import android.content.Intent
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.util.Log
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.MutableStateFlow
import java.util.Locale

class VoiceInputManager(private val context: Context) {

    private val _transcriptionFlow = MutableStateFlow("...")
    val transcriptionFlow: Flow<String> = _transcriptionFlow

    private var speechRecognizer: SpeechRecognizer? = null
    private val speechRecognizerIntent: Intent

    private var isListening = false

    init {
        speechRecognizerIntent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale("es", "ES").toString())
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true)
            putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 5)
        }
    }

    private val recognitionListener = object : RecognitionListener {
        override fun onReadyForSpeech(params: Bundle?) {
             Log.d("VoiceInputManager", "Ready for speech.")
        }

        override fun onBeginningOfSpeech() {
            _transcriptionFlow.value = "Escuchando..."
        }

        override fun onRmsChanged(rmsdB: Float) {}
        override fun onBufferReceived(buffer: ByteArray?) {}
        override fun onEvent(eventType: Int, params: Bundle?) {}

        override fun onEndOfSpeech() {
            Log.d("VoiceInputManager", "End of speech detected.")
            // Restart listening to make it continuous
            if (isListening) {
                speechRecognizer?.startListening(speechRecognizerIntent)
            }
        }

        override fun onError(error: Int) {
            val errorMessage = when (error) {
                SpeechRecognizer.ERROR_NO_MATCH -> "No se ha reconocido voz. Reiniciando..."
                SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> "Silencio detectado. Reiniciando..."
                else -> "Error de reconocimiento: $error"
            }
             Log.e("VoiceInputManager", errorMessage)
            // Restart listening on recoverable errors
            if (isListening && (error == SpeechRecognizer.ERROR_NO_MATCH || error == SpeechRecognizer.ERROR_SPEECH_TIMEOUT)) {
                speechRecognizer?.startListening(speechRecognizerIntent)
            } else {
                 _transcriptionFlow.value = "Error al escuchar. Revisa los permisos del micr√≥fono."
            }
        }

        override fun onResults(results: Bundle?) {
            val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
            if (!matches.isNullOrEmpty()) {
                _transcriptionFlow.value = matches[0]
            }
        }

        override fun onPartialResults(partialResults: Bundle?) {
            val matches = partialResults?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
            if (!matches.isNullOrEmpty()) {
                _transcriptionFlow.value = matches[0]
            }
        }
    }

    /**
     * Starts the real-time listening and transcription process.
     */
    fun startListening() {
        if (!SpeechRecognizer.isRecognitionAvailable(context)) {
            Log.e("VoiceInputManager", "Speech recognition is not available on this device.")
            _transcriptionFlow.value = "Reconocimiento de voz no disponible."
            return
        }
        
        if (isListening) return

        Log.i("VoiceInputManager", "Starting to listen...")
        isListening = true
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context).apply {
            setRecognitionListener(recognitionListener)
            startListening(speechRecognizerIntent)
        }
    }

    /**
     * Stops the listening and transcription process and releases resources.
     */
    fun stopListening() {
        if (!isListening) return

        Log.i("VoiceInputManager", "Stopping listening.")
        isListening = false
        speechRecognizer?.stopListening()
        speechRecognizer?.destroy()
        speechRecognizer = null
        _transcriptionFlow.value = "Modo auditivo desactivado."
    }
}